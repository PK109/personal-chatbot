{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b569362c-e26d-4fdb-93f8-acfa63e0d1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d29535-d9f8-4ff8-980e-2eab74d073a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm_validate = init_chat_model(\"gemini-2.0-flash-lite\", model_provider=\"google_genai\")\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900ab4c-b05c-46d1-8ffc-b1eb613c1916",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "responsive_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are my personal representative. Recruiters might ask you about my skillset and project portfolio and other related things.\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    relativity: str = Field(\n",
    "        description=\"Validate whether user input is related to my skillset, project portfolio or me.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4da682-10fd-4eef-b866-e20bef4d1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "classification_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are my personal representative. Recruiters might ask you about my skillset and project portfolio and other related things.\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class ClassificationTag(BaseModel):\n",
    "\n",
    "    category: str = Field(\n",
    "        description= \"Decide for which category user input is related the most.\",\n",
    "        strict=True,\n",
    "        examples=[\"about Me\", \"gallup\", \"experience\", \"programming\",\"projects\",\"projects\",\"development\",\"other\" ]\n",
    "    )\n",
    "class Classification(BaseModel):\n",
    "\n",
    "    aboutMe: str = Field(\n",
    "        description= \"Validate whether user input is related to me.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    gallup: str = Field(\n",
    "        description= \"Validate whether user input is related to my gallup strenghts\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    experience: str = Field(\n",
    "        description= \"Validate whether user input is related to my experience.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    programming: str = Field(\n",
    "        description= \"Validate whether user input is related to my programming skills.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    projects: str = Field(\n",
    "        description= \"Validate whether user input is related to my project portfolio.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    development: str = Field(\n",
    "        description= \"Validate whether user input is related to my personal development.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm_validate.with_structured_output(ClassificationTag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1566fc5-be05-4ce8-be31-17c0bc066fe0",
   "metadata": {},
   "source": [
    "inp = \"How did you implement change data capture in your portfolio work?\"\n",
    "# inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = classification_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4185e3-b80b-4bc3-93ea-0871992bf5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What was the objective and architecture of your e-commerce workflow project?', 'What was the objective and architecture of your CDC data streaming project?', 'How did you implement change data capture in your portfolio work?', 'How do your projects demonstrate your understanding of end-to-end data pipelines?', 'How have you used Docker and Docker Compose in your data engineering workflows?', 'How did you use Google Cloud tools like BigQuery or GCS in your projects?', 'Can you describe your experience orchestrating workflows?', 'How does your portfolio demonstrate readiness for a data/ai related role?', 'How do your Gallup strengths influence the way you approach data engineering tasks?', 'What areas are you currently focused on improving or learning next?']\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../docs/faq.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    lines = text.split(\"\\n\")\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e930214b-5f0f-4d0b-aa4e-9a7131a1c2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the objective and architecture of your e-commerce workflow project?\n",
      "{'category': 'project portfolio'}\n",
      "What was the objective and architecture of your CDC data streaming project?\n",
      "{'category': 'project objective and architecture'}\n",
      "How did you implement change data capture in your portfolio work?\n",
      "{'category': 'change data capture'}\n",
      "How do your projects demonstrate your understanding of end-to-end data pipelines?\n",
      "{'category': 'Data pipelines'}\n",
      "How have you used Docker and Docker Compose in your data engineering workflows?\n",
      "{'category': 'data engineering'}\n",
      "How did you use Google Cloud tools like BigQuery or GCS in your projects?\n",
      "{'category': 'project'}\n",
      "Can you describe your experience orchestrating workflows?\n",
      "{'category': 'workflow orchestration'}\n",
      "How does your portfolio demonstrate readiness for a data/ai related role?\n",
      "{'category': 'portfolio'}\n",
      "How do your Gallup strengths influence the way you approach data engineering tasks?\n",
      "{'category': 'data engineering'}\n",
      "What areas are you currently focused on improving or learning next\n",
      "{'category': 'skillset'}\n"
     ]
    }
   ],
   "source": [
    "for inp in lines:\n",
    "    prompt = classification_prompt.invoke({\"input\": inp})\n",
    "    response = structured_llm.invoke(prompt)\n",
    "    print(inp[:-1])\n",
    "    print(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6280f34-568d-403e-8693-428a6868fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"True\" in response.model_dump().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a14fbe-0841-41a8-8255-067885f84761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
